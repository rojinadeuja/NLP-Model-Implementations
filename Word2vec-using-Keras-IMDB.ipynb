{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2vec-using-Keras-IMDB.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPYIqQiCyxaM6VWf4Xldtf8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rojinadeuja/NLP-Model-Implementations/blob/master/Word2vec_using_Keras_IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1OPLRTEPW7k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b2e65290-4aa4-4062-e242-92f4e31bb513"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Teh6lFGIPo1R",
        "colab_type": "text"
      },
      "source": [
        "## Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzLvrWAnPnup",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJaijFRMofh-",
        "colab_type": "text"
      },
      "source": [
        "## Load Datatset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7goI5YqP4GE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "0b3db259-8b1b-4235-dde8-4fbf3b78f8d8"
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/IMDB.csv')\n",
        "df.replace(['positive', 'negative'], [1, 0], inplace=True)\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  One of the other reviewers has mentioned that ...          1\n",
              "1  A wonderful little production. <br /><br />The...          1\n",
              "2  I thought this was a wonderful way to spend ti...          1\n",
              "3  Basically there's a family where a little boy ...          0\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBzGy7eoolQR",
        "colab_type": "text"
      },
      "source": [
        "## Data Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoBoDWNvS47A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(s):\n",
        "    '''Function for data pre-processing'''\n",
        "    # Removing html tags\n",
        "    TAG_RE = re.compile(r'<[^>]+>')\n",
        "    sentence = TAG_RE.sub('', s)\n",
        "    \n",
        "    # Remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "\n",
        "    # Single character removal\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    return sentence"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIiuICDWopwf",
        "colab_type": "text"
      },
      "source": [
        "## Create X and y matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_FNd6wLS68Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = []\n",
        "sentences = list(df['review'])\n",
        "for sentence in sentences:\n",
        "    X.append(preprocess(sentence))\n",
        "\n",
        "y = df['sentiment']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcxPOZUIotqB",
        "colab_type": "text"
      },
      "source": [
        "## Split dataset into train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyqEvzwvTdA4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7fbfec40-1be8-42c2-9f8c-68e662fdc373"
      },
      "source": [
        "# Create train-test splits\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "print(len(X_train), len(X_test), len(y_train), len(y_test))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40000 10000 40000 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo0IdqyYT-36",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "43f8763c-1c4b-4b5c-b349-c76449efda17"
      },
      "source": [
        "# Convert into numpy arrays for processing with tensorflo\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "print(type(X_train), type(X_test), type(y_train), type(y_test))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'> <class 'list'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7Wi5tzkoxHn",
        "colab_type": "text"
      },
      "source": [
        "## Tokenize the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHopILhbUAGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize the text\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkN09y0EUF-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding 1 because of reserved 0 index\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "maxlen = 100\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Os_bg7sMo1Pd",
        "colab_type": "text"
      },
      "source": [
        "## Create Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bS3WLQcWdN3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "058a3fee-949f-4c83-9bee-161fb62fa240"
      },
      "source": [
        "# import gensim\n",
        "# path = '/content/drive/My Drive/Colab Notebooks/enwiki_20180420_100d.txt.bz2'\n",
        "# embeddings = gensim.models.KeyedVectors.load_word2vec_format(path, binary = False)\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "model = Word2Vec.load('/content/drive/My Drive/Colab Notebooks/w2v_model_IMDB_100')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rbVhTHmZnrG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.zeros((len(model.wv.vocab), 100)) # vector_dim =100\n",
        "for i in range(len(model.wv.vocab)):\n",
        "    embedding_vector = model.wv[model.wv.index2word[i]]\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySnrYi7-cu-m",
        "colab_type": "text"
      },
      "source": [
        "## Classification using a simple Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEZUUO90gUuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "# Text Classification with a Simple Neural Network\n",
        "vocab_size = len(model.wv.vocab)\n",
        "model = Sequential()\n",
        "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "model.add(embedding_layer)\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Wbfw0NUggWX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "45ae34a7-54c7-4723-db8f-0c500b88d4a5"
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 100)          3364700   \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 10001     \n",
            "=================================================================\n",
            "Total params: 3,374,701\n",
            "Trainable params: 10,001\n",
            "Non-trainable params: 3,364,700\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSD9v6-ypEye",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqIYrPdBhLFD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "ab705854-f6e0-4f7a-92e1-888794a383d8"
      },
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, batch_size=128, epochs=10, verbose=1, validation_split=0.2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5069 - acc: 0.7605 - val_loss: 0.6734 - val_acc: 0.6292\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4981 - acc: 0.7667 - val_loss: 0.6750 - val_acc: 0.6300\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4929 - acc: 0.7660 - val_loss: 0.6864 - val_acc: 0.6279\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4861 - acc: 0.7678 - val_loss: 0.6907 - val_acc: 0.6289\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4808 - acc: 0.7725 - val_loss: 0.6992 - val_acc: 0.6260\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4771 - acc: 0.7747 - val_loss: 0.7055 - val_acc: 0.6300\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4701 - acc: 0.7806 - val_loss: 0.7196 - val_acc: 0.6258\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4683 - acc: 0.7804 - val_loss: 0.7325 - val_acc: 0.6200\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4645 - acc: 0.7823 - val_loss: 0.7310 - val_acc: 0.6209\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4628 - acc: 0.7831 - val_loss: 0.7327 - val_acc: 0.6284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrJyXOpFpI4f",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate model on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nB5hrbEdjSEg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "332ebcfa-63bb-40e8-a5fe-857339674670"
      },
      "source": [
        "# Evaluate the model\n",
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"\\nTest Accuracy:\", score[1])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.7175 - acc: 0.6295\n",
            "\n",
            "Test Accuracy: 0.6294999718666077\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
